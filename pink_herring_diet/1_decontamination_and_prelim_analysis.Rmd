---
title: "Decontamination and first look at ASVs and samples from the pink salmon and herring stomach MiFish metabarcoding"
author: "Kimberly Ledger"
date: "2023-11-17"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Inputs: This code starts with the ASV table output from dada_blast.sh that uses dadasnake for preliminary quality control. We also use sample metadata and a preliminary taxonomic id generated from insect classifier for MiFish for the ASVs in this code.  

Outputs: We will end up with a decontaminated ASV table that can be used for additional analyses.  

Decontamination will involve **these steps**:  

**1. Estimate tag-jumping** - There is the potential for barcodes (that are used to identify the individual samples in a MiSeq run) to be assigned to the wrong sample for a variety of reasons. While we can't tell exactly which mechanism generated these errors, we can still estimate the occurrence of tag-jumping and account for it in our dataset. To do this, we will consider our positive control samples (which have known composition and are extremely unlikely to be present in the environmental samples) as representatives of the amount of tag-jumping occurring across the entire dataset. Specifically, what we will do is subtract the proportion of reads observed in the control samples from each environmental sample. The output will be a dataset with the same number of samples and ASVs as before, but with fewer reads of certain sequences (ASVs). We expect this bias in tag-jumping to be frequency-dependent (i.e. the more abundant ASVs are more likely to be found in samples where they are not suppose to be.)

**2. Remove ASVs with no taxonomic assignment or non-fish assignment** 

**3. Account for contaminants in positive and negative controls** - We can use the reads that show up where we know they shouldn't be (i.e. the controls) to further clean up the dataset. We will remove ASVs that only occur in controls and not in environmental samples. And then we will subtract the maximum number of reads from ASVs found in either the extraction or pcr controls from all samples. The output will be a dataset with the same number of samples as before but with fewer ASVs.  

**4. Discard PCR replicates with low numbers of reads** - Sometimes PCR replicates have low read numbers, and therefore will have skewed relative read proportions. These should be removed.  To do this we will discard samples with <1000 reads. The output will be a dataset with fewer samples and potentially fewer ASVs.  


# Load libraries and data 

load libraries 
```{r}
library(stringi)
library(rstan)
library(broom)
library(tibble)
library(vegan)
library(reshape)
library(tidyverse)
library(dplyr)
```

load ASV table and metadata
```{r}
asv_table <- readRDS("/home/kimberly.ledger/AFSC_eDNA/pink_herring_diet/filtered.seqTab.RDS") %>%
  select(!Row.names)

#transpose 
asv_table <- data.frame(t(asv_table))

#set column names to be ASV# 
colnames(asv_table) <- asv_table["ASV",]

#remove row 
asv_table <- asv_table[-144,]

#make sure reads are numbers
# Convert all character columns to numeric
for (col in names(asv_table)) {
  asv_table[[col]] <- as.numeric(asv_table[[col]])
}

#make make sample ID a column 
asv_table$Sample_ID <- rownames(asv_table)
asv_table$Sample_ID <- as.factor(asv_table$Sample_ID)

metadata <- read.csv("/home/kimberly.ledger/AFSC_eDNA/pink_herring_diet/pinkherring_diet_metadata.csv") %>%
  dplyr::rename(Sample_ID = extraction_ID)

#illumina output changed "_" to "-"
metadata$Sample_ID <- gsub("_", "-", metadata$Sample_ID) 
```

let's start by taking a closer looks at our dataset 
```{r}
## number of ASVs 
sum(grepl("ASV", colnames(asv_table)))  

## number of samples in ASV table 
nrow(asv_table)
```

note: sample name PC-29 is actually the negative control from plate 28 

Before diving into the decontamination steps, let's get a feel for what the data look like. 

### positive controls 

add column to the ASV table that labels the sample type
```{r}
asv_table_with_sample_type <- metadata %>%
  dplyr::select(Sample_ID, sample_type) %>%
  left_join(asv_table, by = "Sample_ID")
```


let's start by visualizing the reads in the positive control samples 
```{r}
asv_table_with_sample_type %>%
  pivot_longer(cols = c(3:413), names_to = "ASV", values_to = "reads") %>%
  filter(sample_type == "positive") %>%
  ggplot(aes(x=Sample_ID, y=reads, fill=ASV)) +
  geom_bar(stat = "identity") + 
    theme_bw() +
  labs(
    y = "number of sequencing reads",
    x = "sample ID",
    title = "ASV reads in positive controls") + 
  theme(
    axis.text.x = element_text(angle = 90, hjust = 0.95),
    legend.text = element_text(size = 8),
    legend.key.size = unit(0.3, "cm"),
    legend.position = "none",
    legend.title = element_blank()
  )
```

top asvs in positive controls
```{r}
asvs_PC <- asv_table_with_sample_type %>%
  pivot_longer(cols = c(3:413), names_to = "ASV", values_to = "reads") %>%
  filter(sample_type == "positive") %>%
  group_by(ASV) %>%
  summarise(total = sum(reads)) %>%
  arrange(desc(total))

head(asvs_PC, 6)
```


### extraction blanks 

let me look into the reads that got into the extraction blanks
```{r}
asv_table_with_sample_type %>%
  pivot_longer(cols = c(3:413), names_to = "ASV", values_to = "reads") %>%
  filter(sample_type == "extraction_blank") %>%
  ggplot(aes(x=Sample_ID, y=reads, fill=ASV)) +
  geom_bar(stat = "identity") + 
    theme_bw() +
  labs(
    y = "number of sequencing reads",
    x = "sample ID",
    title = "ASV reads - extraction blanks") + 
  theme(
    axis.text.x = element_text(angle = 90, hjust = 0.95),
    legend.text = element_text(size = 8),
    legend.key.size = unit(0.3, "cm"),
    legend.position = "none",
    legend.title = element_blank()
  )
```


```{r}
asvs_EC <- asv_table_with_sample_type %>%
  pivot_longer(cols = c(3:413), names_to = "ASV", values_to = "reads") %>%
  filter(sample_type == "extraction_blank") %>%
  group_by(ASV) %>%
  summarise(total = sum(reads)) %>%
  arrange(desc(total))

head(asvs_EC, 10)
```

### pcr blanks 

let me look into the reads that got into the pcr blanks
```{r}
asv_table_with_sample_type %>%
  pivot_longer(cols = c(3:413), names_to = "ASV", values_to = "reads") %>%
  filter(sample_type == "pcr_blank") %>%
  ggplot(aes(x=Sample_ID, y=reads, fill=ASV)) +
  geom_bar(stat = "identity") + 
    theme_bw() +
  labs(
    y = "number of sequencing reads",
    x = "sample ID",
    title = "ASV reads - pcr negatives") + 
  theme(
    axis.text.x = element_text(angle = 90, hjust = 0.95),
    legend.text = element_text(size = 8),
    legend.key.size = unit(0.3, "cm"),
    legend.position = "none",
    legend.title = element_blank()
  )
```

```{r}
asvs_PCRN <- asv_table_with_sample_type %>%
  pivot_longer(cols = c(3:413), names_to = "ASV", values_to = "reads") %>%
  filter(sample_type == "pcr_blank") %>%
  group_by(ASV) %>%
  summarise(total = sum(reads)) %>%
  arrange(desc(total))

head(asvs_PCRN, 10)
```


# 1. Estimate index hopping  
subtract the proportion of reads that jumped into the positive control samples from each environmental sample 

identify the maximum proportion of reads for each ASV found in the positive controls
```{r}
prop_asvs_in_positives <- asv_table_with_sample_type %>%
  #filter(sample_type == "positive") %>%
  filter(Sample_ID == "PC-28") %>%
  pivot_longer(cols = c(3:413), names_to = "ASV", values_to = "reads") %>%
  group_by(Sample_ID) %>%
  mutate(TotalReadsPerSample = sum(reads)) %>%
  mutate(Prop = reads/TotalReadsPerSample) %>%
  group_by(ASV) %>%
  summarise(max_prop = max(Prop))
```

subtract the max proportion of tag-jumped reads for each ASV from all samples
```{r}
indexhop_table <- asv_table_with_sample_type %>%
  pivot_longer(cols = c(3:413), names_to = "ASV", values_to = "reads") %>%
  group_by(Sample_ID) %>%
  mutate(TotalReadsPerSample = sum(reads)) %>%
  left_join(prop_asvs_in_positives, by = "ASV") %>%
  mutate(IndexHoppingReads = TotalReadsPerSample*max_prop) %>%
  mutate(reads_IndexHop_removed = reads - IndexHoppingReads) %>%
  mutate(reads_IndexHop_removed = if_else(reads_IndexHop_removed < 0, 0, reads_IndexHop_removed))
head(indexhop_table)
```


note: since ~25% of reads in one of the positive controls was pink salmon (ASV2), lots of pink salmon reads removed in this step. maybe we don't want to do this...? probably better to be conservative here.  

clean up the table by removing columns no longer needed 
```{r}
asv_table_filter1 <- indexhop_table %>%
  dplyr::select(Sample_ID, sample_type, ASV, reads_IndexHop_removed) %>%
  dplyr::rename(reads = reads_IndexHop_removed)
```

this is a summary of the number of reads removed by ASV and sample_ID
```{r}
decontaminated_1 <- indexhop_table %>%
  dplyr::select(Sample_ID, ASV, IndexHoppingReads) %>%
  pivot_wider(names_from = "ASV", values_from = "IndexHoppingReads")
head(decontaminated_1)
```

and a list of the proportion of reads from ASVs removed 
```{r}
prop_removed_1 <- prop_asvs_in_positives %>%
  arrange(desc(max_prop))
head(prop_removed_1)
```


# 2. Join to taxonomy and get rid of ASVs with no ID 

read in insect taxonomic classifications - keep only ASVs that have an ID 
```{r}
tax <- read.csv("asv_taxonomy_insect.csv") %>%
  dplyr::rename(ASV_num = X) %>%
  filter(rank != "class") %>%  # remove ASVs assigned only to class-level
  filter(rank != "no rank") %>%  #remove ASVs with no taxonomic assignment
  filter(class != "Mammalia")
```

```{r}
asv_table_filter2 <- asv_table_filter1 %>%
  separate(ASV, into = c("ASV_label", "ASV_num"), remove = F) %>%
  mutate(ASV_num = as.integer(ASV_num)) %>%
  filter(ASV_num %in% tax$ASV_num) %>%
  select(!ASV_label) %>%
  select(!ASV_num)
```


# 3. Account for contaminants in positive and negative controls 

next we will remove ASVs that only occur in controls and not in environmental samples. 

let's start by taking a look at what reads remain in these controls 
```{r}
asv_table_filter2 %>%
  filter(sample_type != "sample") %>%
  ggplot(aes(x=Sample_ID, y=reads, fill=ASV)) +
  geom_bar(stat = "identity") + 
    theme_bw() +
  labs(
    y = "number of sequencing reads",
    x = "sample ID",
    title = "ASV reads - controls") + 
  theme(
    axis.text.x = element_text(angle = 90, hjust = 0.95),
    legend.text = element_text(size = 8),
    legend.key.size = unit(0.3, "cm"),
    legend.position = "none",
    legend.title = element_blank()
  )
```

number of reads
```{r}
tempA <- asv_table_filter1 %>%
  group_by(ASV, sample_type) %>%
  summarize(TotalReadsPerASV = sum(reads)) %>%
  arrange(ASV)
```

what ASVs have no reads in samples, but reads in the controls? 
```{r}
tempB <- tempA %>%
  pivot_wider(names_from = "sample_type", values_from = c("TotalReadsPerASV")) %>%
    filter(sample < 1)
head(tempB)
```

remove these from the data frame 
```{r}
asv_table_filter2.5 <- asv_table_filter2 %>%
  filter(!ASV %in% tempB$ASV)
```


how much does this change things?
```{r}
asv_table_filter2.5 %>%
  filter(sample_type != "sample") %>%
  ggplot(aes(x=Sample_ID, y=reads, fill=ASV)) +
  geom_bar(stat = "identity") + 
    theme_bw() +
  labs(
    y = "number of sequencing reads",
    x = "sample ID",
    title = "ASV reads - controls") + 
  theme(
    axis.text.x = element_text(angle = 90, hjust = 0.95),
    legend.text = element_text(size = 8),
    legend.key.size = unit(0.3, "cm"),
    legend.position = "none",
    legend.title = element_blank()
  )
```

next we will subtract the maximum number of reads from ASVs found in the extraction and pcr negative controls from all samples.

calculate the maximum number of reads in an ASV to still show up in an extraction or PCR control 
```{r}
reads_to_remove_per_ASV <- asv_table_filter2.5 %>%
  filter(sample_type == "extraction_blank"| sample_type == "pcr_blank") %>%
  group_by(ASV) %>%
  summarize(max_reads = max(reads))

reads_to_remove_per_sample <- asv_table_filter2.5 %>%
  left_join(reads_to_remove_per_ASV, by = "ASV") %>%
  mutate(read_minus_contamination = reads - max_reads) %>%
  mutate(read_minus_contamination = if_else(read_minus_contamination < 0, 0, read_minus_contamination))
```

filter the data frame 
```{r}
asv_table_filter3 <- reads_to_remove_per_sample %>%
  dplyr::select(!reads) %>%
  dplyr::select(!max_reads) %>%
  dplyr::rename(reads = read_minus_contamination)
```

number of ASVs remaining
```{r}
length(unique(asv_table_filter3$ASV)) 
```

this step does remove a lot of reads from some of the ASVs but i think this is okay since read numbers are quite high and we should see a clear picture of species presence despite removing these reads 



# 4. Discard PCR replicates with low numbers of reads 

calculate reads per sample
```{r}
all_reads <- asv_table_filter3 %>%
  group_by(Sample_ID) %>%
  summarize(ReadsPerSample = sum(reads))
```

visualize 
```{r}
all_reads$x_reordered <- reorder(all_reads$Sample_ID, -all_reads$ReadsPerSample)

all_reads %>%
  ggplot(aes(x = x_reordered, y = ReadsPerSample)) + 
  geom_bar(stat = "identity")
```

fit a normal distribution
```{r}
fit <- MASS::fitdistr(all_reads$ReadsPerSample, "normal")

all_reads %>%  
  mutate(prob = pnorm(all_reads$ReadsPerSample, fit$estimate[[1]], fit$estimate[[2]])) -> all_reads
```

identify and remove the outliers
```{r}
#low_dist_probability_cutoff <- 0.05
minimum_read_cutoff <- 1000

outliers <- all_reads %>% 
  #filter(prob < low_dist_probability_cutoff | ReadsPerSample < minimum_read_cutoff)
  filter(ReadsPerSample < minimum_read_cutoff)

outlierIDs <- outliers$Sample_ID
```

which samples are removed because of the 1000 reads threshold??
```{r}
replicates_removed <- asv_table_filter3 %>%
  filter(Sample_ID %in% outlierIDs) %>%
  pivot_wider(names_from = "ASV", values_from = "reads")
#head(replicates_removed_2)
```

number of pcr replicates removed
```{r}
nrow(replicates_removed)
```

plot them
```{r}
replicates_removed %>%
  pivot_longer(cols = c(3:151), names_to = "ASV", values_to = "count") %>%
ggplot(aes(x=Sample_ID, y=count, fill=ASV)) +
  geom_bar(stat = "identity") + 
    theme_bw() + 
   labs(
    y = "sequencing reads",
    x = "sample ID",
    title = "samples with low read numbers")  +
  theme(
    axis.text.x = element_text(angle = 90, hjust = 0.95),
    legend.position = "none",
    legend.title = element_blank()
  )  
```

filter the data frame 
```{r}
asv_table_filter4 <- asv_table_filter3 %>%
  filter(!Sample_ID %in% outlierIDs)
```


# DONE with read decontamination. 


# join to taxononmy and group reads 
```{r}
taxon_table <- asv_table_filter4 %>%
  separate(ASV, into = c("ASV_label", "ASV_num"), remove = F) %>%
  mutate(ASV_num = as.integer(ASV_num)) %>%
  left_join(tax, by = "ASV_num") %>%
  select(!ASV_label) %>%
  select(!ASV_num) %>% 
  select(!representative) %>%
  select(!taxID) %>%
  select(!score) %>%
  group_by(Sample_ID, taxon, rank, order, family, genus, species) %>%
  summarize(reads = sum(reads))
```

# join the sample metadata so that we know which species of fish the sample came from... 
```{r}
taxon_table_w_meta <- taxon_table %>%
  left_join(metadata, by = "Sample_ID")
```

any taxa have very few reads? 
```{r}
taxa_total <- taxon_table_w_meta %>%
  group_by(taxon) %>%
  summarize(total = sum(reads)) %>%
  arrange(total) %>%
  filter(total < 1000)
```

yes, since the goal of this study is not to identify rare things, i am going to remove any taxa with >1000 reads total across all samples 

```{r}
taxon_table_w_meta <- taxon_table_w_meta %>%
  filter(!taxon %in% taxa_total$taxon)
```

# Pacific herring 

# first let's look at what species are the in Pacific herring stomach samples 
```{r}
herring_stomachs <- taxon_table_w_meta %>% 
  filter(Species == "Pacific herring")

herring_stomachs %>%
  group_by(taxon) %>%
  summarise(total = sum(reads)) %>%
  arrange(desc(total))
```

how many samples? 
```{r}
length(unique(herring_stomachs$Sample_ID))
```

plot reads without herring 
```{r}
herring_stomachs %>%
  filter(family != "Clupeidae") %>%
ggplot(aes(x=Sample_ID, y=reads, fill=taxon)) +
  geom_bar(stat = "identity") + 
    theme_bw() + 
   labs(
    y = "sequencing reads",
    x = "sample ID",
    title = "herring stomachs")  +
  theme(
    axis.text.x = element_text(angle = 90, hjust = 0.95),
    legend.position = "none",
    legend.title = element_blank()
  )  
```

okay, seems like quite a diversity of a taxa here. 

let's start by saying a sample need >1000 non-herring reads in order to establish its diet 
```{r}
herring_diet <- herring_stomachs %>%
  filter(family != "Clupeidae") %>%
  group_by(Sample_ID) %>%
  mutate(ReadsPerSample = sum(reads)) %>%
  filter(ReadsPerSample > 1000) %>%
  mutate(read_prop = reads/ReadsPerSample)
```

how many samples? 
```{r}
length(unique(herring_diet$Sample_ID))
```

plot them - number of reads 
```{r}
herring_diet %>%
ggplot(aes(x=Sample_ID, y=reads, fill=taxon)) +
  geom_bar(stat = "identity") + 
    theme_bw() + 
   labs(
    y = "number  of sequencing reads",
    x = "sample ID",
    title = "herring stomachs")  +
  theme(
    axis.text.x = element_text(angle = 90, hjust = 0.95),
    legend.position = "none",
    legend.title = element_blank()
  )  
```

plot them - proportion 
```{r}
herring_diet %>%
ggplot(aes(x=Sample_ID, y=read_prop, fill=taxon)) +
  geom_bar(stat = "identity") + 
    theme_bw() + 
   labs(
    y = "proportion of sequencing reads",
    x = "sample ID",
    title = "herring stomachs")  +
  theme(
    axis.text.x = element_text(angle = 90, hjust = 0.95),
    legend.position = "none",
    legend.title = element_blank()
  )  
```

what taxa are these colors? 
```{r}
for_legend <- herring_diet %>%
  ggplot(aes(x=Sample_ID, y=read_prop, fill=taxon)) +
  geom_bar(stat = "identity") + 
  theme_bw() +
  theme(
    axis.text.x = element_blank(),
    legend.position = "right",
    legend.text = element_text(size = 7),
    legend.title = element_blank()
  )  

library(grid)
library(gridExtra) 

# Using the cowplot package
legend <- cowplot::get_legend(for_legend)

grid.newpage()
grid.draw(legend)
```

still pretty hard to tell what's what.  should have someone verify that these taxa look okay. i.e. nothing from outside the range 

let's make a list of what taxa make up at least 25% of the reads in at least one sample 
```{r}
herring_diet %>%
  filter(read_prop >= 0.25) %>%
  group_by(taxon) %>%
  summarize(num = n()) %>%
  arrange(desc(num))
```

okay, not much pink salmon.  part of this might be due to so many pink salmon reads being removed during decontamination... but it's hard to say whether or not those are not contamination.  

are there any salmon reads in samples now? 

how many samples have pink salmon reads that make up >5% of reads 
```{r}
herring_diet %>%
  filter(taxon == "Oncorhynchus gorbuscha" & reads > 0)

herring_diet %>%
  filter(taxon == "Oncorhynchus" & reads > 0)
```

okay, it seems unlikely that pink salmon are apart of herring diet.  

# Pink salmon 

# first let's look at what species are the in Pacific herring stomach samples 
```{r}
pink_stomachs <- taxon_table_w_meta %>% 
  filter(Species == "Pink salmon")

pink_stomachs %>%
  group_by(taxon) %>%
  summarise(total = sum(reads)) %>%
  arrange(desc(total))
```


how many samples? 
```{r}
length(unique(pink_stomachs$Sample_ID))
```

plot reads without salmon reads - i'm guessing that all Oncorhynchus reads here are from the pink salmon even though their taxon assignments differ... unless pink salmon fry eat chum or other salmon??? 
```{r}
pink_stomachs %>%
  filter(taxon != "Oncorhynchus gorbuscha") %>% 
  filter(taxon != "Oncorhynchus") %>%
  filter(taxon != "Oncorhynchus keta") %>%  
ggplot(aes(x=Sample_ID, y=reads, fill=taxon)) +
  geom_bar(stat = "identity") + 
    theme_bw() + 
   labs(
    y = "sequencing reads",
    x = "sample ID",
    title = "pink salmon stomachs")  +
  theme(
    axis.text.x = element_text(angle = 90, hjust = 0.95),
    legend.position = "none",
    legend.title = element_blank()
  )  
```

okay, not many taxa here and only in a few samples. 

let's start by saying a sample need >1000 non-herring reads in order to establish its diet 
```{r}
pink_diet <- pink_stomachs %>%
  filter(taxon != "Oncorhynchus gorbuscha") %>% 
  filter(taxon != "Oncorhynchus") %>%
  filter(taxon != "Oncorhynchus keta") %>%
  group_by(Sample_ID) %>%
  mutate(ReadsPerSample = sum(reads)) %>%
  filter(ReadsPerSample > 1000) %>%
  mutate(read_prop = reads/ReadsPerSample)
```

how many samples? 
```{r}
length(unique(pink_diet$Sample_ID))
```

plot them
```{r}
pink_diet %>%
ggplot(aes(x=Sample_ID, y=reads, fill=taxon)) +
  geom_bar(stat = "identity") + 
    theme_bw() + 
   labs(
    y = "number of sequencing reads",
    x = "sample ID",
    title = "pink salmon stomachs")  +
  theme(
    axis.text.x = element_text(angle = 90, hjust = 0.95),
    legend.position = "none",
    legend.title = element_blank()
  )  
```

plot them
```{r}
pink_diet %>%
ggplot(aes(x=Sample_ID, y=read_prop, fill=taxon)) +
  geom_bar(stat = "identity") + 
    theme_bw() + 
   labs(
    y = "proportion of sequencing reads",
    x = "sample ID",
    title = "pink salmon stomachs")  +
  theme(
    axis.text.x = element_text(angle = 90, hjust = 0.95),
    legend.position = "none",
    legend.title = element_blank()
  )  
```

what taxa are these colors? 
```{r}
for_legend <- pink_diet %>%
  ggplot(aes(x=Sample_ID, y=read_prop, fill=taxon)) +
  geom_bar(stat = "identity") + 
  theme_bw() +
  theme(
    axis.text.x = element_blank(),
    legend.position = "right",
    legend.text = element_text(size = 7),
    legend.title = element_blank()
  )  

library(grid)
library(gridExtra) 

# Using the cowplot package
legend <- cowplot::get_legend(for_legend)

grid.newpage()
grid.draw(legend)
```


let's make a list of what taxa make up at least 25% of the reads in at least one sample 
```{r}
pink_diet %>%
  filter(read_prop >= 0.25) %>%
  group_by(taxon) %>%
  summarize(num = n()) %>%
  arrange(desc(num))
```

herring in 4 of the pink salmon stomachs  

